# Important Elasticsearch configuration
Elasticsearchを使い始めるにはほとんど設定が必要ありませんが、クラスターを実運用で使用する前に考慮しなければならない項目がいくつかあります。

Elastic Cloudサービスは、これらの項目を自動的に設定し、お客様のクラスタをデフォルトで本番環境に対応させます。

## Path settings
Elasticsearchは、インデックスを作成したデータをindexに、データストリームをdataディレクトリに書き込みます。Elasticsearchは、クラスタの健全性や操作に関する情報を含む独自のアプリケーションログをlogsディレクトリに書き込みます。

macOS .tar.gz、Linux .tar.gz、Windows .zip のインストールでは、デフォルトで data と logs は $ES_HOME のサブディレクトリになります。ただし、$ES_HOME内のファイルはアップグレード時に削除される危険性があります。

実運用では、elasticsearch.ymlのpath.dataとpath.logsを$ES_HOME以外の場所に設定することを強くお勧めします。Docker、Debian、RPMのインストールでは、デフォルトでデータとログを$ES_HOME外の場所に書き出します。

サポートされるpath.dataとpath.logsの値はプラットフォームによって異なります。

Unix-like systems
LinuxとmacOSのインストールは、Unixスタイルのパスをサポートしています。

```
path:
  data: /var/data/elasticsearch
  logs: /var/log/elasticsearch
```

データディレクトリの内容を変更したり、その内容に干渉するようなプロセ スを実行しないでください。Elasticsearch以外のものがデータディレクトリの内容を変更した場合、Elasticsearchが失敗し、破損やその他のデータの不一致を報告する可能性があります。データディレクトリのファイルシステムバックアップを取ろうとしないでください。このようなバックアップを復元する方法はサポートされていません。代わりに、スナップショットと復元を使用して安全にバックアップを取得してください。データ・ディレクトリでウィルス・スキャナを実行しないでください。ウィルススキャナは、Elasticsearchの正常な動作を妨げ、データディレクトリのコンテンツを変更する可能性があります。データディレクトリには実行ファイルは含まれていませんので、ウィルススキャンは誤検出をするだけです。

## Multiple data paths
Deprecated in 7.13.0.

必要であれば、path.dataで複数のパスを指定することができます。Elasticsearch は提供されたすべてのパスにわたってノードのデータを保存しますが、各シャードのデータは同じパスに保持されます。

Elasticsearch は、ノードのデータパス間でシャードのバランスを取りません。単一のパスでディスク使用量が多い場合、ノード全体のディスク使用量が多いウォーターマークがトリガーされることがあります。この場合、そのノードの他のパスにディスク容量があっても、Elasticsearchはそのノードにシャードを追加しません。追加のディスクスペースが必要な場合は、データパスを追加するのではなく、新しいノードを追加することをお勧めします。

Unix-like systems
Linux and macOS installations support multiple Unix-style paths in path.data:

```
path:
  data:
    - /mnt/elasticsearch_1
    - /mnt/elasticsearch_2
    - /mnt/elasticsearch_3
```

## Migrate from multiple data paths
複数のデータパスのサポートは 7.13 で非推奨となり、将来のリリースで削除される予定です。

複数のデータパスの代わりに、RAIDなどのハードウェア仮想化レイヤーや、LinuxのLVM（Logical Volume Manager）、WindowsのStorage Spacesなどのソフトウェア仮想化レイヤーで、複数のディスクにまたがるファイルシステムを作成することができます。1台のマシンで複数のデータパスを使用する場合、データパスごとに1つのノードを実行する必要があります。

現在、高可用性クラスタで複数のデータパスを使用している場合、ローリング・リスタートに似たプロセスを使用して、ダウンタイムなしに各ノードで単一パスを使用するセットアップに移行することができます：各ノードを順番に停止して、それぞれ単一データパスを使用するように構成された1つまたは複数のノードに置き換えます。より詳細には、現在複数のデータパスを持つ各ノードについて、以下のプロセスを実行する必要があります。原則的に、この移行は 8.0 へのローリングアップグレード中に実行できますが、アップグレードを開始する前に単一データパス設定に移行することをお勧めします。

1. 災害時にデータを保護するために、スナップショットを取得します。
2. オプションで、アロケーションフィルタを使用してターゲットノードからデータを移行します。

```
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.exclude._name": "target-node-name"
  }
}
```

cat allocation API を使用して、このデータ移行の進捗を追跡することができます。一部のシャードが移行されない場合、クラスタ割り当ての説明APIがその理由を判断するのに役立ちます。

3. ターゲットノードのシャットダウンまで、ローリング再起動プロセスのステップに従います。
4. クラスタの健全性が黄色または緑色であることを確認し、クラスタの他のノードの少なくとも 1 つに割り当てられたすべてのシャードのコピーが存在することを確認します。
5. 該当する場合は、先の手順で適用した割り当てフィルタを削除します。

```
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.exclude._name": null
  }
}
```

6. 停止したノードのデータパスの内容を削除して、ノードの持つデータを破棄します。
7. ストレージを再構成する。例えば、LVMやStorage Spacesを使用して、ディスクを1つのファイルシステムにまとめます。再構成されたストレージに、保持するデータに対して十分なスペースがあることを確認します。
8. elasticsearch.ymlファイルのpath.dataの設定を調整して、ノードを再設定してください。必要であれば、別のデータパスを指す独自のpath.data設定を持つノードをさらにインストールします。
9. 新しいノードを起動し、残りのローリングリスタートプロセスに従います。
10. クラスタのヘルスがグリーンであることを確認し、すべてのシャードが割り当てられていることを確認します。

また、シングルデータパスのノードをいくつかクラスタに追加し、アロケーションフィルタを使用してすべてのデータを新しいノードにマイグレートしてから、古いノードをクラスタから削除することもできます。この方法では、クラスタのサイズが一時的に2倍になるため、このようにクラスタを拡張できる容量がある場合にのみ有効です。

現在複数のデータパスを使用しているが、クラスタが高可用性でない場合は、スナップショットを取得し、目的の構成で新しいクラスタを作成し、スナップショットをそこにリストアすることによって、非推奨の構成に移行することができます。

## Cluster name setting
ノードがクラスタに参加できるのは、クラスタの他のすべてのノードとcluster.nameを共有する場合のみです。デフォルトの名前はelasticsearchですが、クラスタの目的を説明する適切な名前に変更する必要があります。

```
cluster.name: logging-prod
```

異なる環境で同じクラスタ名を再利用しないでください。そうしないと、ノードが間違ったクラスタに参加する可能性があります。

## Node name setting
lasticsearchは、Elasticsearchの特定のインスタンスのための人間が読める識別子として、node.nameを使用しています。この名前は多くのAPIのレスポンスに含まれます。ノード名のデフォルトはElasticsearchの起動時のマシンのホスト名ですが、elasticsearch.ymlで明示的に設定することもできます。

```
node.name: prod-data-2
```

## Network host setting
デフォルトでは、Elasticsearchは127.0.0.1や[::1]などのループバックアドレスにのみバインドされます。開発やテスト用に1台のサーバで1ノード以上のクラスタを動かすにはこれで十分ですが、弾力性のある本番用クラスタには他のサーバ上のノードが含まれる必要があります。多くのネットワーク設定がありますが、通常、設定する必要があるのはnetwork.hostだけです。

```
network.host: 192.168.1.10
```

network.hostに値を与えると、Elasticsearchは開発モードから本番モードへの移行を想定し、多くのシステム起動時のチェックを警告から例外にアップグレードします。開発モードと本番モードの違いをご覧ください。

## Discovery and cluster formation settings
クラスタ内のノードが互いに検出し、マスターノードを選出できるように、運用開始前に2つの重要な検出およびクラスタ形成設定を構成する。

`discovery.seed_hosts`
ネットワーク設定をしなくても、Elasticsearchは利用可能なループバックアドレスにバインドし、ローカルポート9300から9305をスキャンして、同じサーバで動作する他のノードと接続します。この動作により、何も設定することなく、自動クラスター化を実現します。

他のホスト上のノードとクラスターを形成したい場合は、静的な discovery.seed_hosts 設定を使用します。この設定は、クラスタ内の他のノードのうち、マスター資格のある、ライブで接触可能なノードのリストを提供し、発見プロセスの種にします。この設定は、クラスタ内のすべてのマスター適格ノードのアドレスのYAMLシーケンスまたはアレイを受け付けます。各アドレスは、IPアドレス、またはDNSを介して1つ以上のIPアドレスに解決するホスト名のいずれかになります。

```
discovery.seed_hosts:
   - 192.168.1.10:9300
   - 192.168.1.11 ---1
   - seeds.mydomain.com ---2
   - [0:0:0:0:0:ffff:c0a8:10c]:9301 ---3
```

1. ポートはオプションで、デフォルトは9300ですが、オーバーライドすることができます。
2. ホスト名が複数のIPアドレスに解決される場合、ノードは解決されたすべてのアドレスで他のノードを発見しようとします。
3. IPv6アドレスは角括弧で囲む必要があります。

マスター資格のあるノードが固定名や固定アドレスを持たない場合、代替ホストプロバイダを使用してアドレスを動的に検索します。

`cluster.initial_master_nodes`
Elasticsearchクラスタを初めて起動する際、クラスタブートストラップステップにより、最初の選挙でカウントされるマスター適格ノードのセットが決定されます。開発モードでは、ディスカバリの設定がされていないため、このステップはノード自身によって自動的に実行されます。

自動ブートストラップは本質的に安全ではないため、運用モードで新しいクラスタを開始する際には、最初の選挙でカウントされるマスター資格のあるノードを明示的にリストアップする必要があります。このリストは cluster.initial_master_nodes 設定を使用して設定します。

クラスタが初めて正常に形成された後、各ノードの設定からcluster.initial_master_nodes設定を削除します。クラスタを再起動するときや、既存のクラスタに新しいノードを追加するときは、この設定を使用しないでください。

```
discovery.seed_hosts:
   - 192.168.1.10:9300
   - 192.168.1.11
   - seeds.mydomain.com
   - [0:0:0:0:0:ffff:c0a8:10c]:9301
cluster.initial_master_nodes: ---1
   - master-node-a
   - master-node-b
   - master-node-c
```

1. 初期マスターノードを node.name (デフォルトはホスト名) で識別します。cluster.initial_master_nodesの値がnode.nameに正確に一致することを確認します。ノード名にmaster-node-a.example.comのような完全修飾ドメイン名（FQDN）を使用する場合は、このリストにFQDNを使用する必要があります。逆に、node.nameが末尾の修飾子を持たない素のホスト名である場合、cluster.initial_master_nodesの末尾の修飾子も省略する必要があります。

クラスタのブートストラップおよびディスカバリとクラスタ形成の設定を参照してください。

## Heap size settings
デフォルトでは、Elasticsearchはノードの役割と総メモリ量に基づいて、自動的にJVMヒープサイズを設定します。ほとんどの実稼働環境では、このデフォルトのサイジングを推奨します。

必要であれば、JVMヒープサイズを手動で設定することにより、デフォルトのサイジングをオーバーライドすることができます。

## JVM heap dump path setting
デフォルトでは、Elasticsearchは、メモリ不足の例外発生時にヒープをデフォルトのデータディレクトリにダンプするようにJVMを構成します。RPMとDebianパッケージでは、データディレクトリは/var/lib/elasticsearchです。LinuxとMacOS、Windowsのディストリビューションでは、データディレクトリはElasticsearchのインストール先のルート下にあります。

このパスがヒープダンプの受信に適していない場合は、jvm.options の -XX:HeapDumpPath=... というエントリを修正してください。

- ディレクトリを指定した場合、JVMは実行中のインスタンスのPIDに基づいてヒープダンプ用のファイル名を生成します。
- ディレクトリの代わりに固定ファイル名を指定した場合、JVMがメモリ不足の例外でヒープ・ダンプを実行する必要があるときに、そのファイルが存在してはなりません。そうでなければ、ヒープ・ダンプは失敗します。

## GC logging settings
デフォルトでは、Elasticsearchはガベージコレクション（GC）ログを有効にします。これは jvm.options で設定され、Elasticsearch のログと同じデフォルトの場所に出力されます。デフォルトのコンフィギュレーションでは、64MBごとにログがローテーションされ、最大2GBのディスクスペースを消費することがあります。

JEP 158で説明されているコマンドラインオプションを使用して、JVMロギングを再構成することができます。統合 JVM ログ」で説明されているコマンドラインオプションを使用して、JVM ログを再構成できます。デフォルトのjvm.optionsファイルを直接変更しない限り、独自の設定に加え、Elasticsearchのデフォルト設定が適用されます。デフォルトの設定を無効にするには、まず -Xlog:disable オプションを指定してロギングを無効化し、次に独自のコマンドラインオプションを指定します。これは、全てのJVMロギングを無効にするので、利用可能なオプションを確認し、必要なものを全て有効にしてください。

オリジナルのJEPに含まれていない他のオプションを見るには、「JVM Unified Logging Frameworkでログを有効にする」を参照してください。

## Examples
ES_HOME/config/jvm.options.d/gc.options を作成し、いくつかのサンプルオプションを使用して、デ フォルトの GC ログ出力場所を /opt/my-app/gc.log に変更します。

```
# Turn off all previous logging configuratons
-Xlog:disable

# Default settings from JEP 158, but with `utctime` instead of `uptime` to match the next line
-Xlog:all=warning:stderr:utctime,level,tags

# Enable GC logging to a custom location with a variety of options
-Xlog:gc*,gc+age=trace,safepoint:file=/opt/my-app/gc.log:utctime,pid,tags:filecount=32,filesize=64m
```

GCデバッグログを標準エラー（stderr）に送信するようにElasticsearch Dockerコンテナを構成する。これにより、コンテナオーケストレーターが出力を処理することができます。ES_JAVA_OPTS 環境変数を使用する場合は、指定します。

```
MY_OPTS="-Xlog:disable -Xlog:all=warning:stderr:utctime,level,tags -Xlog:gc=debug:stderr:utctime"
docker run -e ES_JAVA_OPTS="$MY_OPTS" # etc
```

## Temporary directory settings
デフォルトでは、Elasticsearchは、スタートアップスクリプトがシステム一時ディレクトリの直下に作成するプライベート一時ディレクトリを使用します。

一部のLinuxディストリビューションでは、最近アクセスされていないファイルやディレクトリは、システムユーティリティによって/tmpから削除されることがあります。この動作により、一時ディレクトリを必要とする機能が長期間使用されない場合、Elasticsearchの実行中にプライベート一時ディレクトリが削除される可能性があります。プライベート一時ディレクトリを削除すると、その後にこのディレクトリを必要とする機能が使用された場合に問題が発生します。

.deb または .rpm パッケージを使用して Elasticsearch をインストールし、systemd で実行する場合、Elasticsearch が使用するプライベート一時ディレクトリは定期的なクリーンアップの対象から除外されます。

LinuxやMacOSで.tar.gzを長期間使用する場合は、Elasticsearch専用の一時ディレクトリを作成し、古いファイルやディレクトリがクリーンアップされないようなパス配下に置くことを検討してください。このディレクトリは、Elasticsearchを実行するユーザのみがアクセスできるようにパーミッションを設定する必要があります。そして、Elasticsearchを起動する前に、$ES_TMPDIR環境変数にこのディレクトリを指すように設定します。

## JVM fatal error log setting
のデフォルトロギングディレクトリです。RPMおよびDebianパッケージでは、このディレクトリは/var/log/elasticsearchです。Linux、MacOS、Windowsのディストリビューションでは、logsディレクトリはElasticsearchインストールのルート下に位置します。

これらは、JVMがセグメンテーション・フォールトのような致命的なエラーに遭遇したときに生成されるログです。このパスがログの受信に適していない場合は、jvm.optionsの-XX:ErrorFile=...のエントリを修正してください。

## Cluster backups
災害時には、スナップショットによって永久的なデータ損失を防ぐことができます。スナップショットのライフサイクル管理は、クラスタの定期的なバックアップを取るための最も簡単な方法です。詳細については、「スナップショットを作成する」を参照してください。

スナップショットの作成は、クラスタをバックアップするための唯一の信頼できる方法であり、サポートされています。Elasticsearchクラスタのノードのデータディレクトリのコピーを作成することによって、クラスタをバックアップすることはできません。ファイルシステムレベルのバックアップからデータをリストアする方法はサポートされていません。このようなバックアップからクラスタをリストアしようとすると、ファイルの破損や欠落、その他のデータの不整合が報告されて失敗したり、データの一部を静かに失って成功したかのように見えることがあります。
